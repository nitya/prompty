# Streaming Example

Prompty can be configured to use streaming responses.

Refer to the [streaming.prompty](#filepath: /workspaces/prompty/runtime/promptycs/Prompty.Core.Tests/prompty/streaming.prompty) file for more examples.

```yaml
---
name: Streaming Example
description: A prompt that uses streaming responses
authors:
  - example_author
model:
  api: chat
  configuration:
    azure_deployment: gpt-35-turbo
  parameters:
    stream: true
    stream_options:
      include_usage: true
sample:
  question: What is the weather like today?
---
system:
You are a helpful assistant.
user:
{{question}}
```
